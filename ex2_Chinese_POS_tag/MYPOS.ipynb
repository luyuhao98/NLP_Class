{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "## 42类标注\n",
    "state_set=['nz', 'Bg', 'nr', 'h', 'Mg', 's', 'nt', 'Ng', 'k', 'p', 'e', 'Rg', 'r', 'y', 't', 'q', 'n', 'ns', 'Vg', 'm', 'vd', 'nx', 'vn', 'i', 'z', 'u', 'b', 'w', 'Ag', 'j', 'c', 'l', 'v', 'd', 'a', 'f', 'o', 'ad', 'Tg', 'an', 'Yg', 'Dg']\n",
    "trans = {}\n",
    "emit = {}\n",
    "start = {}\n",
    "count_dic = {}  #每个状态在训练集中出现的次数\n",
    "line_num = 0    #训练集语句数量\n",
    "word_set = set()    #训练数据集中所有字的集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化所有概率矩阵\n",
    "def Init_Array():\n",
    "    for state0 in state_set:\n",
    "        trans[state0] = {}\n",
    "        for state1 in state_set:\n",
    "            trans[state0][state1] = 0.0\n",
    "    for state in state_set:\n",
    "        start[state] = 0.0\n",
    "        emit[state] = {}\n",
    "        emit[state]['unknown']=0;\n",
    "        count_dic[state] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将参数估计的概率取对数，对概率0取无穷小-3.14e+100\n",
    "def Prob_Array():\n",
    "    for key in start:\n",
    "        if start[key] == 0:\n",
    "            start[key] = -3.14e+100\n",
    "        else:\n",
    "            start[key] = np.log(start[key] / line_num)\n",
    "    for key0 in trans:\n",
    "        for key1 in trans[key0]:\n",
    "#             if trans[key0][key1] == 0.0:\n",
    "#                 trans[key0][key1] = -3.14e+100\n",
    "#             else:\n",
    "            trans[key0][key1] = np.log(1+trans[key0][key1] / count_dic[key0]+len(trans[key0]))\n",
    "    # print(trans)\n",
    "    for key in emit:\n",
    "        for word in emit[key]:\n",
    "#             if emit[key][word] == 0.0:\n",
    "#                 emit[key][word] = -3.14e+100\n",
    "#             else:\n",
    "            #add one smoothing\n",
    "            emit[key][word] = np.log((emit[key][word]+1) /(count_dic[key]+len(emit[key])))\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Viterbi算法求测试集最优状态序列\n",
    "def Viterbi(sentence,array_pi,array_a,array_b):\n",
    "    tab = [{}]  #动态规划表\n",
    "    path = {}\n",
    "\n",
    "    for state in state_set:\n",
    "        #print(array_pi)\n",
    "        \n",
    "        #发射矩阵中某状态不存在该首字符sentence[0],则概率降至最低\n",
    "        if sentence[0] not in array_b[state]:\n",
    "            array_b[state][sentence[0]] = -3.14e+100\n",
    "        tab[0][state] = array_pi[state] + array_b[state][sentence[0]]\n",
    "        path[state] = [state]\n",
    "    for i in range(1,len(sentence)):\n",
    "        tab.append({})\n",
    "        new_path = {}\n",
    "        for state0 in state_set:\n",
    "            items = []\n",
    "            for state1 in state_set:\n",
    "                if sentence[i] not in array_b[state0]:  #所有在测试集出现但没有在训练集中出现的字符\n",
    "                    prob = tab[i - 1][state1] + array_a[state1][state0] + array_b[state0]['unknown']\n",
    "                else:\n",
    "                    prob = tab[i-1][state1] + array_a[state1][state0] + array_b[state0][sentence[i]]    #计算每个字符对应STATES的概率\n",
    "                items.append((prob,state1))\n",
    "           \n",
    "            best = max(items)   #best:(prob,state)\n",
    "            # print(best)\n",
    "            tab[i][state0] = best[0]\n",
    "            # print(tab[i][state0])\n",
    "            new_path[state0] = path[best[1]] + [state0]\n",
    "        path = new_path\n",
    "\n",
    "    prob, state = max([(tab[len(sentence) - 1][state], state) for state in state_set])\n",
    "    return path[state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(str):\n",
    "    print(\"training \",str)\n",
    "    global state_set\n",
    "    global line_num\n",
    "    trainset = open(str, encoding='utf-8')     #读取训练集1\n",
    "    loop_num = 0\n",
    "    for line in trainset:\n",
    "        line = line.strip()\n",
    "        if not len(line):\n",
    "            continue\n",
    "        line_num+=1\n",
    "        \n",
    "        global state_set\n",
    "        word_list=[]\n",
    "        state_list=[]\n",
    "        \n",
    "        ntflag = False\n",
    "        stdline = \"\"\n",
    "        templine = \"\"\n",
    "        for k in range(len(line)):\n",
    "            if not ntflag :\n",
    "                if line[k] == '[':\n",
    "                    ntflag = True\n",
    "                else:\n",
    "                    stdline += line[k]\n",
    "            else :\n",
    "                if line[k] == ']':\n",
    "                    templist = templine.split()\n",
    "                    templine =\"\"\n",
    "                    for item in templist:\n",
    "                        item = item.split('/')\n",
    "                        stdline+=item[0]\n",
    "                    stdline+='/'\n",
    "                    ntflag = False\n",
    "                else:\n",
    "                    templine+=line[k]\n",
    "        # print(stdline)            \n",
    "        stdlist = stdline.split()\n",
    "        \n",
    "        for i in range(1,len(stdlist)):\n",
    "            item = stdlist[i].split('/')\n",
    "            # print(item)\n",
    "            word_list.append(item[0])\n",
    "            state_list.append(item[1])\n",
    "        \n",
    "        start[state_list[0]] += 1\n",
    "        \n",
    "        \n",
    "        for j in range(len(state_list)-1):\n",
    "            trans[state_list[j]][state_list[j+1]] += 1  #trans计算状态转移概率\n",
    "\n",
    "        for p in range(len(state_list)):\n",
    "            count_dic[state_list[p]] += 1  # 记录每一个状态的出现次数\n",
    "            for state in state_set:\n",
    "                if word_list[p] not in emit[state]:\n",
    "                    emit[state][word_list[p]] = 0.0  #保证每个字都在state_set的字典中\n",
    "            emit[state_list[p]][word_list[p]] += 1  # emit用于计算发射概率\n",
    "\n",
    "#     print('参数估计结果')\n",
    "#     print('初始状态分布')\n",
    "#     print(start)\n",
    "#     print('状态转移矩阵')\n",
    "#     print(trans)\n",
    "#     print('发射矩阵')\n",
    "#     print(emit)\n",
    "    #    state_set = state_set | set(state_list)\n",
    "        \n",
    "    #     print(loop_num)\n",
    "        loop_num +=1\n",
    "    #     if(loop_num ==10): break;\n",
    "    #print(loop_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(str):\n",
    "    print(\"start to predict\",str)\n",
    "    testset = open(str, encoding='utf-8')       #读取测试集\n",
    "    word_num = 0\n",
    "    correct_num = 0\n",
    "    line_counter = 0\n",
    "    for line in testset:\n",
    "        line = line.strip()\n",
    "        if len(line)==0:continue #跳过空行\n",
    "        line_counter+=1\n",
    "        if line_counter%50==0:\n",
    "            print(line_counter)\n",
    "        if line_counter==1000:\n",
    "            break;\n",
    "        ntflag = False\n",
    "        stdline = \"\"\n",
    "        templine = \"\"\n",
    "        for k in range(len(line)):\n",
    "            if not ntflag :\n",
    "                if line[k] == '[':\n",
    "                    ntflag = True\n",
    "                else:\n",
    "                    stdline += line[k]\n",
    "            else :\n",
    "                if line[k] == ']':\n",
    "                    templist = templine.split()\n",
    "                    templine =\"\"\n",
    "                    for item in templist:\n",
    "                        item = item.split('/')\n",
    "                        stdline+=item[0]\n",
    "                    stdline+='/'\n",
    "                    ntflag = False\n",
    "                else:\n",
    "                    templine+=line[k]\n",
    "        # print(stdline)            \n",
    "        stdlist = stdline.split()\n",
    "        \n",
    "        word_list=[]\n",
    "        key_state_list=[]\n",
    "        #test_state_list=[]\n",
    "        \n",
    "        for i in range(len(stdlist)):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            item = stdlist[i].split('/')\n",
    "            # print(item)\n",
    "            word_list.append(item[0])\n",
    "            key_state_list.append(item[1])\n",
    "        \n",
    "        word_num += len(word_list)\n",
    "        \n",
    "        test_state_list = Viterbi(word_list, start, trans, emit)\n",
    "        \n",
    "        \n",
    "        for i in range(len(key_state_list)):\n",
    "            if(key_state_list[i]==test_state_list[i]):\n",
    "                correct_num += 1\n",
    "    precision = correct_num/word_num\n",
    "    print(\"precision:\",precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalid(filelist):\n",
    "    for i in range(len(filelist)):\n",
    "        print(i)\n",
    "        Init_Array()\n",
    "        for j in range(len(filelist)):\n",
    "            if j!=i:\n",
    "                train(filelist[j])\n",
    "        Prob_Array()\n",
    "        print(start)\n",
    "        predict(filelist[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "training  ./data/199802.txt\n",
      "training  ./data/199803.txt\n",
      "training  ./data/199804.txt\n",
      "{'nz': -5.194494379010218, 'Bg': -3.14e+100, 'nr': -2.0699612720593965, 'h': -3.14e+100, 'Mg': -3.14e+100, 's': -6.236434280579417, 'nt': -2.6841605977678915, 'Ng': -7.140404528065531, 'k': -3.14e+100, 'p': -2.3229247772311683, 'e': -8.393167496560899, 'Rg': -3.14e+100, 'r': -2.2580665349701996, 'y': -11.032224826176158, 't': -2.6552136653597826, 'q': -8.729639733182111, 'n': -2.1462305110233473, 'ns': -2.7627240589955426, 'Vg': -7.203583429687063, 'm': -2.4995520639115334, 'vd': -7.813349001307957, 'nx': -7.535717264709677, 'vn': -4.749958079280151, 'i': -5.510763908313911, 'z': -6.989173558341608, 'u': -11.032224826176158, 'b': -5.124141888007227, 'w': -2.7252589608075835, 'Ag': -8.46727546871462, 'j': -4.002251914469771, 'c': -4.061494748032632, 'l': -4.898826783179509, 'v': -2.4083320161008643, 'd': -3.865958852042519, 'a': -4.3652680337469505, 'f': -5.938474625369395, 'o': -10.339077645616213, 'ad': -5.4638803224150605, 'Tg': -6.905090441131066, 'an': -8.087785847009718, 'Yg': -3.14e+100, 'Dg': -9.933612537508047}\n",
      "start to predict ./data/199801.txt\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "precision: 0.8279905295200872\n",
      "1\n",
      "training  ./data/199801.txt\n",
      "training  ./data/199803.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-67aa0f5e0f19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilelist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'./data/199801.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'./data/199802.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'./data/199803.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'./data/199804.txt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcrossvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilelist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-5d61cc9f0823>\u001b[0m in \u001b[0;36mcrossvalid\u001b[0;34m(filelist)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilelist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilelist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mProb_Array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-23b0f691d363>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(str)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mcount_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# 记录每一个状态的出现次数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0memit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m  \u001b[0;31m#保证每个字都在state_set的字典中\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filelist = ['./data/199801.txt','./data/199802.txt','./data/199803.txt','./data/199804.txt']\n",
    "crossvalid(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob_Array()\n",
    "# predict('./data/199801.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
